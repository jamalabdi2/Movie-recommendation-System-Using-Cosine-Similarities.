{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n"
      ],
      "metadata": {
        "id": "EMkc9W2MNrFr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BASE_URL = 'https://www.imdb.com'\n",
        "def clean_year(year:str) -> int:\n",
        "    \"\"\"Clean up a year string.\"\"\"\n",
        "    cleaned_year = year.replace('(','').replace(')','')\n",
        "    try:\n",
        "        if '–' in cleaned_year:\n",
        "            years = cleaned_year.split('–')\n",
        "            return [int(year) for year in years]\n",
        "        else:\n",
        "            return int(year.replace('(','').replace(')',''))\n",
        "    except Exception as e:\n",
        "        if 'TV Movie' in year or 'Video' in year:\n",
        "          year = year.split(' ')[0].replace('(','').replace(')','')\n",
        "        elif any(suffix in year for suffix in ('(I)', '(II)', '(III)','(VII)','VI')):\n",
        "          year = year.split(' ')[1].replace('(','').replace(')','')\n",
        "        else:\n",
        "          return None\n",
        " \n",
        "        return year\n",
        "\n",
        "\n",
        "\n",
        "def extract_metascore(metascore_tag):\n",
        "    \"\"\"Extract metascore from a BeautifulSoup tag.\"\"\"\n",
        "    try:\n",
        "        result = metascore_tag.text.strip()\n",
        "        return result\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "\n",
        "def extract_votes(votes_gross_tags):\n",
        "    \"\"\"Extract votes from a list of BeautifulSoup tags.\"\"\"\n",
        "    try:\n",
        "        votes = votes_gross_tags[0].text\n",
        "        return votes\n",
        "    except:\n",
        "      return None\n",
        "\n",
        "\n",
        "\n",
        "def extract_gross(votes_gross_tags):\n",
        "    \"\"\"Extract gross from a list of BeautifulSoup tags.\"\"\"\n",
        "    try:\n",
        "        if len(votes_gross_tags) !=2:\n",
        "            gross = None\n",
        "        else:\n",
        "            gross = votes_gross_tags[1].text\n",
        "        return gross\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def extract_certificate(certificate):\n",
        "  try:\n",
        "    rating_cert = certificate.text.replace('-','')\n",
        "    return rating_cert\n",
        "  except:\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_runtime(runtime):\n",
        "  try:\n",
        "    runtime = runtime.text.split(' ')[0]\n",
        "    return runtime\n",
        "  except:\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_ratings(rating):\n",
        "  try:\n",
        "    rating = rating.text\n",
        "    return rating\n",
        "  except:\n",
        "    return None"
      ],
      "metadata": {
        "id": "2JgS00DVma__"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_all_data():\n",
        "    \"\"\"Scrape data from multiple pages and return as a pandas DataFrame.\"\"\"\n",
        "    all_data = []\n",
        "    for pagenumber in range(0,30):\n",
        "        url = f'https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page={pagenumber}'\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status() # Raise an exception if status code is not 200\n",
        "            print(f'The request to {url} was successful')\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            all_movies = soup.find_all('div',{'class':'lister-item mode-detail'})\n",
        "            for movie in all_movies:\n",
        "                data = {}\n",
        "                data['Title'] = movie.find('h3').find('a').text\n",
        "                data['Movie Url'] = BASE_URL + movie.find('h3').find('a')['href']\n",
        "                data['Year'] = clean_year(movie.find('span',{'class':'lister-item-year text-muted unbold'}).text)\n",
        "                data['Certificate'] = extract_certificate(movie.find('span',{'class','certificate'}))\n",
        "                data['Genre'] = movie.find('span',{'class','genre'}).text.strip().split(',')\n",
        "                data['Runtime'] = extract_runtime(movie.find('span',{'class':'runtime'}))\n",
        "                data['Metascore'] = extract_metascore(movie.find('span',{'class':'metascore'}))\n",
        "                data['Rating'] = extract_ratings(movie.find('span',{'class','ipl-rating-star__rating'}))\n",
        "                data['Description'] = movie.find('p',{'class',''}).text.strip()\n",
        "                data['Director'] = movie.find_all('p',{'class':'text-muted text-small'})[1].find('a').text\n",
        "                data['Stars'] = [star.text for star in movie.find_all('p',{'class':'text-muted text-small'})[1].find_all('a')[1:]]\n",
        "                data['Votes'] = extract_votes(movie.find_all('span',{'name':'nv'}))\n",
        "                data['Gross'] = extract_gross(movie.find_all('span',{'name':'nv'}))\n",
        "                data['Movie Poster'] = movie.find('div', {'class':'lister-item-image ribbonize'}).find('img')['loadlate']\n",
        "                all_data.append(data)\n",
        "        except Exception as e:\n",
        "            print(f'The requests to {url} failed. {e}')\n",
        "    return pd.DataFrame(all_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "tR3w_3-ENxw0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataframe = get_all_data()\n",
        "movie_dataframe.to_csv('imdb_movies.csv', sep='\\t', encoding='utf-8')\n",
        "movie_dataframe.to_excel('idmb_movies.xlsx', index=False)\n",
        "movie_dataframe.to_json('idmb.json',orient='records',indent=4)"
      ],
      "metadata": {
        "id": "nIburGb7N1aA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d5b4cd-94a6-4c0e-e64d-6c5460e919bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=0 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=1 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=2 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=3 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=4 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=5 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=6 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=7 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=8 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=9 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=10 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=11 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=12 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=13 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=14 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=15 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=16 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=17 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=18 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=19 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=20 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=21 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=22 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=23 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=24 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=25 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=26 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=27 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=28 was successful\n",
            "The request to https://www.imdb.com/list/ls074451163/?sort=list_order,asc&st_dt=&mode=detail&page=29 was successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataframe.head(10)['Movie Poster'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "wnn-IuQz2rRq",
        "outputId": "afd51915-3b7c-4094-b402-af814e9b10b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://m.media-amazon.com/images/M/MV5BM2MyNjYxNmUtYTAwNi00MTYxLWJmNWYtYzZlODY3ZTk3OTFlXkEyXkFqcGdeQXVyNzkwMjQ5NzM@._V1_UY209_CR3,0,140,209_AL_.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}